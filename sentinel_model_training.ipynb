{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LfxiHz0goe5y",
        "6jfwRvD59RyX",
        "X0MyBsZnTrnh"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sentinel-FYP/colab_notebooks/blob/main/sentinel_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uE7UIt2rEkL",
        "outputId": "4b5d77d3-fecd-481a-f5ee-7717958f613b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies and Set Constants"
      ],
      "metadata": {
        "id": "lg2stKU9oZgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies"
      ],
      "metadata": {
        "id": "LfxiHz0goe5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm opencv-python opencv-python-headless tf-models-official\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w133-W0-oida",
        "outputId": "65008970-bd76-4db9-d782-da54239ef9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.1.78)\n",
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.14.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (3.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (3.7.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.1.3)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (6.0.1)\n",
            "Collecting sacrebleu (from tf-models-official)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.11.3)\n",
            "Collecting sentencepiece (from tf-models-official)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.14.0 (from tf-models-official)\n",
            "  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.14.0 (from tf-models-official)\n",
            "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (16.0.6)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (4.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (1.59.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.5.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.14.0->tf-models-official) (0.41.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (6.1.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (3.2.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=92645f89e6b41cecc5c53a2e92e027b5ff401489531301e7e8a2dacb270f9111\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, wrapt, tensorflow-model-optimization, tensorflow-estimator, portalocker, ml-dtypes, keras, immutabledict, colorama, sacrebleu, seqeval, tensorboard, tensorflow, tensorflow-text, tf-models-official\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.15.0\n",
            "    Uninstalling wrapt-1.15.0:\n",
            "      Successfully uninstalled wrapt-1.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.13.0\n",
            "    Uninstalling tensorflow-estimator-2.13.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.1\n",
            "    Uninstalling ml-dtypes-0.3.1:\n",
            "      Successfully uninstalled ml-dtypes-0.3.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.13.1\n",
            "    Uninstalling keras-2.13.1:\n",
            "      Successfully uninstalled keras-2.13.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.13.0\n",
            "    Uninstalling tensorboard-2.13.0:\n",
            "      Successfully uninstalled tensorboard-2.13.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.13.0\n",
            "    Uninstalling tensorflow-2.13.0:\n",
            "      Successfully uninstalled tensorflow-2.13.0\n",
            "Successfully installed colorama-0.4.6 immutabledict-3.0.0 keras-2.14.0 ml-dtypes-0.2.0 portalocker-2.8.2 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.14.0 tf-models-official-2.14.0 wrapt-1.14.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Packages"
      ],
      "metadata": {
        "id": "XhwycXykolyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import zipfile as zf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython import display\n",
        "from urllib import request\n",
        "from tensorflow_docs.vis import embed\n",
        "\n",
        "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
        "from official.projects.movinet.modeling import movinet\n",
        "from official.projects.movinet.modeling import movinet_model\n",
        "from official.projects.movinet.tools import export_saved_model"
      ],
      "metadata": {
        "id": "y6q5kcYaooRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Hyperparams"
      ],
      "metadata": {
        "id": "czh8PfxIpFdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "batch_size = 1\n",
        "resolution = 172\n",
        "num_frames = 64\n",
        "frame_step = 1\n",
        "dropout_rate=0.\n",
        "bias_regularizer=0.\n",
        "epochs = 5\n",
        "model_id = 'a0'\n",
        "export_model = False\n",
        "start_from_checkpoint = True\n",
        "evaluate = False\n",
        "export_model_name = 'a0_stream_5.0'\n",
        "frame_shape = (num_frames, resolution, resolution, 3)\n",
        "input_shape = (batch_size, num_frames, resolution, resolution, 3)"
      ],
      "metadata": {
        "id": "tUdv4u9KpG7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Directory Structure"
      ],
      "metadata": {
        "id": "6qUTC4broxiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {}\n",
        "paths['root'] = pathlib.Path('/content/drive/MyDrive/ucf_dataset')\n",
        "assert paths['root'].exists() == True\n",
        "paths['models'] = (paths['root'] / 'models' / model_id)\n",
        "paths['tflite'] = (paths['root'] / 'tf_lite_models' / model_id)\n",
        "paths['checkpoints_dir'] = (paths['root'] / 'checkpoints' / model_id / export_model_name)"
      ],
      "metadata": {
        "id": "w_wXBxDQo1VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in paths.values():\n",
        "  assert p.exists()"
      ],
      "metadata": {
        "id": "FeTnH_SVrei3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "f3Rmb4tOsOWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Annotations"
      ],
      "metadata": {
        "id": "YOnMufiUsZY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = pd.read_csv(paths['root'] / 'frame_annotations.csv')\n",
        "annotations = annotations.set_index('file_name')\n",
        "annotations['binary_class'] = annotations['is_annomaly'].map({1.0 : 'Anomaly', 0.0 : \"Normal\"})"
      ],
      "metadata": {
        "id": "4nGn-ihnsVRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Helper Functions"
      ],
      "metadata": {
        "id": "Ehg8I5xDsgXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(fname):\n",
        "  \"\"\" Retrieve the name of the class given a filename/file_path.\n",
        "\n",
        "    Args:\n",
        "      fname: Name of the file in the UCF Crime dataset.\n",
        "    Returns:\n",
        "      Class that the file belongs to.\n",
        "  \"\"\"\n",
        "  fname = fname.split('/')[-1]\n",
        "  class_name = fname.split('_')[0]\n",
        "  #remove numbers\n",
        "  class_name = ''.join(char for char in class_name if not char.isnumeric())\n",
        "  if class_name == \"Normal\":\n",
        "    return \"Normal\"\n",
        "  else:\n",
        "    return \"Anomaly\""
      ],
      "metadata": {
        "id": "9kblnaORsjd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_frames(frame, output_size):\n",
        "  \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "\n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "  \"\"\"\n",
        "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "  return frame"
      ],
      "metadata": {
        "id": "GbXirjoKuj_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_annotations(video_path, annotations_df=annotations):\n",
        "  video_name = str(video_path).split(\"/\")[-1]\n",
        "  return annotations_df.loc[video_name].to_dict()"
      ],
      "metadata": {
        "id": "Xw7elBnhumAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def frames_from_video_file(video_path, n_frames, output_size, frame_step):\n",
        "#   \"\"\"\n",
        "#     Creates frames from each video file present for each category.\n",
        "\n",
        "#     Args:\n",
        "#       video_path: File path to the video.\n",
        "#       n_frames: Number of frames to be created per video file.\n",
        "#       output_size: Pixel size of the output frame image.\n",
        "\n",
        "#     Return:\n",
        "#       An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "#   \"\"\"\n",
        "#   # Read each video frame by frame\n",
        "#   video_annotations = get_video_annotations(video_path)\n",
        "#   result = []\n",
        "#   src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "#   video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "#   need_length = 1 + (n_frames - 1) * frame_step\n",
        "#   if video_annotations['anomaly_1_start'] == -1:\n",
        "#     if need_length > video_length:\n",
        "#       start = 0\n",
        "#       end = video_length\n",
        "#     else:\n",
        "#       max_start = video_length - need_length\n",
        "#       start = random.randint(0, max_start + 1)\n",
        "#       end = start + need_length\n",
        "#   else:\n",
        "#     start = video_annotations['anomaly_1_start']\n",
        "#     end = video_annotations['anomaly_1_end']\n",
        "#   src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "#   # ret is a boolean indicating whether read was successful, frame is the image itself\n",
        "#   ret, frame = src.read()\n",
        "#   frame_count = start + 1;\n",
        "#   result.append(format_frames(frame, output_size))\n",
        "\n",
        "#   for _ in range(n_frames - 1):\n",
        "#     for _ in range(frame_step):\n",
        "#       ret, frame = src.read()\n",
        "#       frame_count += 1;\n",
        "#     if ret and frame_count < end and frame is not None:\n",
        "#       frame = format_frames(frame, output_size)\n",
        "#       result.append(frame)\n",
        "#     else:\n",
        "#       break\n",
        "#   src.release()\n",
        "#   result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "#   return result"
      ],
      "metadata": {
        "id": "oJzxSG3LunaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_from_video_file(video_path, n_frames, output_size, frame_step):\n",
        "  \"\"\"\n",
        "    Creates frames from each video file present for each category.\n",
        "\n",
        "    Args:\n",
        "      video_path: File path to the video.\n",
        "      n_frames: Number of frames to be created per video file.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "  \"\"\"\n",
        "  # Read each video frame by frame\n",
        "  video_annotations = get_video_annotations(video_path)\n",
        "  result = []\n",
        "  src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  need_length = n_frames\n",
        "  if video_annotations['anomaly_1_start'] == -1:\n",
        "    if need_length > video_length:\n",
        "      start = 0\n",
        "      end = video_length\n",
        "    else:\n",
        "      max_start = video_length - need_length\n",
        "      start = random.randint(0, max_start)\n",
        "      end = start + need_length\n",
        "  else:\n",
        "    start = video_annotations['anomaly_1_start']\n",
        "    end = video_annotations['anomaly_1_end']\n",
        "    if need_length < (end - start):\n",
        "      max_start = end - need_length\n",
        "      start = random.randint(start, max_start)\n",
        "      end = start + need_length\n",
        "\n",
        "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "\n",
        "  for _ in range(n_frames):\n",
        "    ret, frame = src.read()\n",
        "    if ret and frame is not None:\n",
        "      frame = format_frames(frame, output_size)\n",
        "      result.append(frame)\n",
        "    else:\n",
        "      break\n",
        "  src.release()\n",
        "  result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "mfcjyCuM-3en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset Paths"
      ],
      "metadata": {
        "id": "of2cwEy2tAUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_paths = {}\n",
        "dataset_directory = pathlib.Path('/content/drive/MyDrive/ucf_extracted')\n",
        "dataset_paths['train'] = dataset_directory / 'train'\n",
        "dataset_paths['test'] = dataset_directory / 'test'"
      ],
      "metadata": {
        "id": "kUCjbw8HtNFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in dataset_paths.values():\n",
        "  assert p.exists() == True"
      ],
      "metadata": {
        "id": "Mf4SoN-ftzk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_count_train = len(list(dataset_directory.glob('train/*/*.mp4')))\n",
        "video_count_test = len(list(dataset_directory.glob('test/*/*.mp4')))\n",
        "video_total = video_count_train + video_count_test\n",
        "print(f'Total training videos: {video_count_train}')\n",
        "print(f'Total training test: {video_count_test}')\n",
        "print(f\"Total videos: {video_total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeAKdV5OuPBO",
        "outputId": "0f5554b5-2b8f-4eeb-fc66-8d21f642a532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training videos: 849\n",
            "Total training test: 150\n",
            "Total videos: 999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset Generator\n"
      ],
      "metadata": {
        "id": "spN6fp2yus56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameGenerator:\n",
        "  def __init__(self, path, n_frames=num_frames, output_size=(resolution, resolution), frame_step=frame_step, training = False):\n",
        "    \"\"\" Returns a set of frames with their associated label.\n",
        "\n",
        "      Args:\n",
        "        path: Video file paths.\n",
        "        n_frames: Number of frames.\n",
        "        training: Boolean to determine if training dataset is being created.\n",
        "    \"\"\"\n",
        "    self.path = path\n",
        "    self.n_frames = n_frames\n",
        "    self.training = training\n",
        "    self.output_size = output_size\n",
        "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
        "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
        "\n",
        "  def get_files_and_class_names(self):\n",
        "    video_paths = list(self.path.glob('*/*.mp4'))\n",
        "    classes = [p.parent.name for p in video_paths]\n",
        "    return video_paths, classes\n",
        "\n",
        "  def __call__(self):\n",
        "    video_paths, classes = self.get_files_and_class_names()\n",
        "    pairs = list(zip(video_paths, classes))\n",
        "    if self.training:\n",
        "      random.shuffle(pairs)\n",
        "    for path, name in pairs:\n",
        "      try:\n",
        "        video_frames = frames_from_video_file(path, self.n_frames, output_size=self.output_size, frame_step=frame_step)\n",
        "      except Exception as exc:\n",
        "        print(f'Error on {path}')\n",
        "        print(exc)\n",
        "        continue\n",
        "      label = self.class_ids_for_name[name] # Encode labels\n",
        "      yield video_frames, label\n"
      ],
      "metadata": {
        "id": "UtaJ5n13uwvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_signature = (tf.TensorSpec(shape =(None, resolution, resolution, 3), dtype = tf.float32),\n",
        "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(dataset_paths['train'], training = True),\n",
        "                                          output_signature=output_signature\n",
        "                                          )\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(FrameGenerator(dataset_paths['test']),\n",
        "                                        output_signature=output_signature\n",
        "                                         )\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "JrHUIK7PvfvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frames, labels in train_ds.take(1):\n",
        "  print(f\"Frames Shape: {frames.shape}, Dtype: {frames.dtype}\")\n",
        "  print(f\"Label Shape: {labels.shape}, Dtype: {labels.dtype}\")"
      ],
      "metadata": {
        "id": "4UR5-EbI3Rtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac0cf1e-9ad6-41fa-8603-eaa5d37b087e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames Shape: (1, 64, 172, 172, 3), Dtype: <dtype: 'float32'>\n",
            "Label Shape: (1,), Dtype: <dtype: 'int16'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "# test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "mWWG0-u99FQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Loading"
      ],
      "metadata": {
        "id": "E4V56xn8xWnG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmdzt6Eu9Afp"
      },
      "source": [
        "### Construct the backbone with proper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msnxCHSa9Cb2"
      },
      "outputs": [],
      "source": [
        "use_positional_encoding = model_id in {'a3', 'a4', 'a5'}\n",
        "\n",
        "backbone = movinet.Movinet(\n",
        "    model_id=model_id,\n",
        "    causal=True,\n",
        "    conv_type='2plus1d',\n",
        "    se_type='2plus3d',\n",
        "    activation='hard_swish',\n",
        "    gating_activation='hard_sigmoid',\n",
        "    use_positional_encoding=use_positional_encoding,\n",
        "    use_external_states=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSCnGqY69IzG"
      },
      "source": [
        "### Construct the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5m9qZ__eo92"
      },
      "outputs": [],
      "source": [
        "if not start_from_checkpoint:\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone,\n",
        "      num_classes=600,\n",
        "      output_states=True)\n",
        "\n",
        "  model.build(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jfwRvD59RyX"
      },
      "source": [
        "### Load the pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7y8zwcz9SJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00d529b-173a-47ed-dc15-857d751d60a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movinet_a0_stream/\n",
            "movinet_a0_stream/ckpt-1.data-00000-of-00001\n",
            "movinet_a0_stream/ckpt-1.index\n",
            "movinet_a0_stream/checkpoint\n"
          ]
        }
      ],
      "source": [
        "if not start_from_checkpoint:\n",
        "  # Extract pretrained weights\n",
        "  !wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_stream.tar.gz -O movinet_a0_stream.tar.gz -q\n",
        "  !tar -xvf movinet_a0_stream.tar.gz\n",
        "\n",
        "  checkpoint_dir = 'movinet_a0_stream'\n",
        "  checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "  checkpoint = tf.train.Checkpoint(model=model)\n",
        "  status = checkpoint.restore(checkpoint_path)\n",
        "  status.assert_existing_objects_matched()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0MyBsZnTrnh"
      },
      "source": [
        "### Set up the distribution strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHyqT0csQvRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe37afb-8722-446a-da07-29d51640536c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on single GPU  /device:GPU:0\n",
            "Number of accelerators:  1\n"
          ]
        }
      ],
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu_resolver = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "  tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n",
        "  print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  distribution_strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  distribution_strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  distribution_strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "\n",
        "print(\"Number of accelerators: \", distribution_strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmPbIku_9ejS"
      },
      "source": [
        "### Construct custom classifier with required number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpXf9GFWlE2-"
      },
      "outputs": [],
      "source": [
        "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes, dropout_rate, bias_regularizer):\n",
        "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone=backbone,\n",
        "      num_classes=num_classes,\n",
        "      dropout_rate=dropout_rate,\n",
        "      bias_regularizer=tf.keras.regularizers.L2(bias_regularizer))\n",
        "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Construct loss, optimizer and compile the model\n",
        "with distribution_strategy.scope():\n",
        "  model = build_classifier(batch_size, None, resolution, backbone, num_classes, dropout_rate, bias_regularizer)\n",
        "  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "  model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start From Previous Checkpoint"
      ],
      "metadata": {
        "id": "0o9sYkeu1Pwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if start_from_checkpoint:\n",
        "  model.load_weights(tf.train.latest_checkpoint(paths['checkpoints_dir']))\n",
        "  print('Loading from: ',tf.train.latest_checkpoint(paths['checkpoints_dir']))"
      ],
      "metadata": {
        "id": "w_GyI3Ho1Tm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3S6pmEO9y9w"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=paths['checkpoints_dir'] / 'cp.ckpt',\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "OWbdFNdk2_Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_ds,\n",
        "                    validation_data=test_ds,\n",
        "                    epochs=epochs,\n",
        "                    validation_freq=1,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "P5Q7qA5hxOD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17009aa1-f756-4159-da2d-b2b9d3b230ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "    849/Unknown - 1088s 1s/step - loss: 0.2862 - accuracy: 0.8846\n",
            "Epoch 1: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1290s 2s/step - loss: 0.2862 - accuracy: 0.8846 - val_loss: 0.9896 - val_accuracy: 0.6600\n",
            "Epoch 2/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.2780 - accuracy: 0.8728\n",
            "Epoch 2: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1309s 2s/step - loss: 0.2780 - accuracy: 0.8728 - val_loss: 0.9545 - val_accuracy: 0.6333\n",
            "Epoch 3/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9105\n",
            "Epoch 3: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1289s 2s/step - loss: 0.2195 - accuracy: 0.9105 - val_loss: 1.2549 - val_accuracy: 0.6667\n",
            "Epoch 4/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9199\n",
            "Epoch 4: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1306s 2s/step - loss: 0.2087 - accuracy: 0.9199 - val_loss: 1.1443 - val_accuracy: 0.7000\n",
            "Epoch 5/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9388\n",
            "Epoch 5: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1317s 2s/step - loss: 0.1822 - accuracy: 0.9388 - val_loss: 1.5132 - val_accuracy: 0.5733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "z38g9CV9x7W6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot History"
      ],
      "metadata": {
        "id": "RwpiMfItyXDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "%matplotlib inline\n",
        "plt.figure()\n",
        "plot_training_history(results)"
      ],
      "metadata": {
        "id": "uthxcrfFyS9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "363530d4-cd32-4248-81ad-39303b41e1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting Model"
      ],
      "metadata": {
        "id": "tNvQGrqiAAV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstruct the whole model with use_external_states=True to make the inference using states."
      ],
      "metadata": {
        "id": "qZUK0Rqv21uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if export_model:\n",
        "  model_id = 'a0'\n",
        "  use_positional_encoding = model_id in {'a3', 'a4', 'a5'}\n",
        "\n",
        "  # Create backbone and model.\n",
        "  backbone = movinet.Movinet(\n",
        "      model_id=model_id,\n",
        "      causal=True,\n",
        "      conv_type='2plus1d',\n",
        "      se_type='2plus3d',\n",
        "      activation='hard_swish',\n",
        "      gating_activation='hard_sigmoid',\n",
        "      use_positional_encoding=use_positional_encoding,\n",
        "      use_external_states=True,\n",
        "  )\n",
        "\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone,\n",
        "      num_classes=num_classes,\n",
        "      output_states=True)\n",
        "\n",
        "\n",
        "  # [Optional] Build the model and load a pretrained checkpoint.\n",
        "  model.build(input_shape)\n",
        "\n",
        "  # Load weights from the checkpoint to the rebuilt model\n",
        "  model.load_weights(tf.train.latest_checkpoint(paths['checkpoints_dir']))"
      ],
      "metadata": {
        "id": "vmd7kZL4nQ9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export to saved model"
      ],
      "metadata": {
        "id": "HEYDIVSr3NUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if export_model:\n",
        "  saved_model_dir = paths['models'] / export_model_name\n",
        "  tflite_filename = paths['tflite']  / (export_model_name + \".tflite\")\n",
        "  # Convert to saved model\n",
        "  export_saved_model.export_saved_model(\n",
        "      model=model,\n",
        "      input_shape=[1, 1, resolution, resolution, 3],\n",
        "      export_path=saved_model_dir,\n",
        "      causal=True,\n",
        "      bundle_input_init_states_fn=False)"
      ],
      "metadata": {
        "id": "reOX9Zskneql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to TF Lite"
      ],
      "metadata": {
        "id": "pePv8slH4yOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if export_model:\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(str(saved_model_dir))\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  with open(tflite_filename, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "nFXGX9nr4xeU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}