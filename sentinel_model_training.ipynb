{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LfxiHz0goe5y",
        "6jfwRvD59RyX",
        "X0MyBsZnTrnh"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sentinel-FYP/colab_notebooks/blob/main/sentinel_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uE7UIt2rEkL",
        "outputId": "4b5d77d3-fecd-481a-f5ee-7717958f613b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies and Set Constants"
      ],
      "metadata": {
        "id": "lg2stKU9oZgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies"
      ],
      "metadata": {
        "id": "LfxiHz0goe5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm opencv-python opencv-python-headless tf-models-official\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w133-W0-oida",
        "outputId": "65008970-bd76-4db9-d782-da54239ef9a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.1.78)\n",
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.14.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (3.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (3.7.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.1.3)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (6.0.1)\n",
            "Collecting sacrebleu (from tf-models-official)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.11.3)\n",
            "Collecting sentencepiece (from tf-models-official)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.14.0 (from tf-models-official)\n",
            "  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.14.0 (from tf-models-official)\n",
            "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.0.6)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (16.0.6)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (4.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.14.0->tf-models-official) (1.59.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0 (from tensorflow~=2.14.0->tf-models-official)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.5.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.14.0->tf-models-official) (0.41.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (6.1.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.14.0->tf-models-official) (3.2.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=92645f89e6b41cecc5c53a2e92e027b5ff401489531301e7e8a2dacb270f9111\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, wrapt, tensorflow-model-optimization, tensorflow-estimator, portalocker, ml-dtypes, keras, immutabledict, colorama, sacrebleu, seqeval, tensorboard, tensorflow, tensorflow-text, tf-models-official\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.15.0\n",
            "    Uninstalling wrapt-1.15.0:\n",
            "      Successfully uninstalled wrapt-1.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.13.0\n",
            "    Uninstalling tensorflow-estimator-2.13.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.1\n",
            "    Uninstalling ml-dtypes-0.3.1:\n",
            "      Successfully uninstalled ml-dtypes-0.3.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.13.1\n",
            "    Uninstalling keras-2.13.1:\n",
            "      Successfully uninstalled keras-2.13.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.13.0\n",
            "    Uninstalling tensorboard-2.13.0:\n",
            "      Successfully uninstalled tensorboard-2.13.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.13.0\n",
            "    Uninstalling tensorflow-2.13.0:\n",
            "      Successfully uninstalled tensorflow-2.13.0\n",
            "Successfully installed colorama-0.4.6 immutabledict-3.0.0 keras-2.14.0 ml-dtypes-0.2.0 portalocker-2.8.2 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.14.0 tf-models-official-2.14.0 wrapt-1.14.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Packages"
      ],
      "metadata": {
        "id": "XhwycXykolyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import zipfile as zf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython import display\n",
        "from urllib import request\n",
        "from tensorflow_docs.vis import embed\n",
        "\n",
        "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
        "from official.projects.movinet.modeling import movinet\n",
        "from official.projects.movinet.modeling import movinet_model\n",
        "from official.projects.movinet.tools import export_saved_model"
      ],
      "metadata": {
        "id": "y6q5kcYaooRH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Hyperparams"
      ],
      "metadata": {
        "id": "czh8PfxIpFdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "batch_size = 1\n",
        "resolution = 172\n",
        "num_frames = 64\n",
        "frame_step = 1\n",
        "dropout_rate=0.\n",
        "bias_regularizer=0.\n",
        "epochs = 5\n",
        "model_id = 'a0'\n",
        "export_model = False\n",
        "start_from_checkpoint = False\n",
        "evaluate = False\n",
        "export_model_name = 'a0_stream_5.0'\n",
        "frame_shape = (num_frames, resolution, resolution, 3)\n",
        "input_shape = (batch_size, num_frames, resolution, resolution, 3)"
      ],
      "metadata": {
        "id": "tUdv4u9KpG7I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Directory Structure"
      ],
      "metadata": {
        "id": "6qUTC4broxiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {}\n",
        "paths['root'] = pathlib.Path('/content/drive/MyDrive/ucf_dataset')\n",
        "assert paths['root'].exists() == True\n",
        "paths['models'] = (paths['root'] / 'models' / model_id)\n",
        "paths['tflite'] = (paths['root'] / 'tf_lite_models' / model_id)\n",
        "paths['checkpoints_dir'] = (paths['root'] / 'checkpoints' / model_id / export_model_name)"
      ],
      "metadata": {
        "id": "w_wXBxDQo1VW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in paths.values():\n",
        "  assert p.exists()"
      ],
      "metadata": {
        "id": "FeTnH_SVrei3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "f3Rmb4tOsOWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Annotations"
      ],
      "metadata": {
        "id": "YOnMufiUsZY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = pd.read_csv(paths['root'] / 'frame_annotations.csv')\n",
        "annotations = annotations.set_index('file_name')\n",
        "annotations['binary_class'] = annotations['is_annomaly'].map({1.0 : 'Anomaly', 0.0 : \"Normal\"})"
      ],
      "metadata": {
        "id": "4nGn-ihnsVRx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Helper Functions"
      ],
      "metadata": {
        "id": "Ehg8I5xDsgXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(fname):\n",
        "  \"\"\" Retrieve the name of the class given a filename/file_path.\n",
        "\n",
        "    Args:\n",
        "      fname: Name of the file in the UCF Crime dataset.\n",
        "    Returns:\n",
        "      Class that the file belongs to.\n",
        "  \"\"\"\n",
        "  fname = fname.split('/')[-1]\n",
        "  class_name = fname.split('_')[0]\n",
        "  #remove numbers\n",
        "  class_name = ''.join(char for char in class_name if not char.isnumeric())\n",
        "  if class_name == \"Normal\":\n",
        "    return \"Normal\"\n",
        "  else:\n",
        "    return \"Anomaly\""
      ],
      "metadata": {
        "id": "9kblnaORsjd1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_frames(frame, output_size):\n",
        "  \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "\n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "  \"\"\"\n",
        "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "  return frame"
      ],
      "metadata": {
        "id": "GbXirjoKuj_R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_annotations(video_path, annotations_df=annotations):\n",
        "  video_name = str(video_path).split(\"/\")[-1]\n",
        "  return annotations_df.loc[video_name].to_dict()"
      ],
      "metadata": {
        "id": "Xw7elBnhumAt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def frames_from_video_file(video_path, n_frames, output_size, frame_step):\n",
        "#   \"\"\"\n",
        "#     Creates frames from each video file present for each category.\n",
        "\n",
        "#     Args:\n",
        "#       video_path: File path to the video.\n",
        "#       n_frames: Number of frames to be created per video file.\n",
        "#       output_size: Pixel size of the output frame image.\n",
        "\n",
        "#     Return:\n",
        "#       An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "#   \"\"\"\n",
        "#   # Read each video frame by frame\n",
        "#   video_annotations = get_video_annotations(video_path)\n",
        "#   result = []\n",
        "#   src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "#   video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "#   need_length = 1 + (n_frames - 1) * frame_step\n",
        "#   if video_annotations['anomaly_1_start'] == -1:\n",
        "#     if need_length > video_length:\n",
        "#       start = 0\n",
        "#       end = video_length\n",
        "#     else:\n",
        "#       max_start = video_length - need_length\n",
        "#       start = random.randint(0, max_start + 1)\n",
        "#       end = start + need_length\n",
        "#   else:\n",
        "#     start = video_annotations['anomaly_1_start']\n",
        "#     end = video_annotations['anomaly_1_end']\n",
        "#   src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "#   # ret is a boolean indicating whether read was successful, frame is the image itself\n",
        "#   ret, frame = src.read()\n",
        "#   frame_count = start + 1;\n",
        "#   result.append(format_frames(frame, output_size))\n",
        "\n",
        "#   for _ in range(n_frames - 1):\n",
        "#     for _ in range(frame_step):\n",
        "#       ret, frame = src.read()\n",
        "#       frame_count += 1;\n",
        "#     if ret and frame_count < end and frame is not None:\n",
        "#       frame = format_frames(frame, output_size)\n",
        "#       result.append(frame)\n",
        "#     else:\n",
        "#       break\n",
        "#   src.release()\n",
        "#   result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "#   return result"
      ],
      "metadata": {
        "id": "oJzxSG3LunaF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_from_video_file(video_path, n_frames, output_size, frame_step):\n",
        "  \"\"\"\n",
        "    Creates frames from each video file present for each category.\n",
        "\n",
        "    Args:\n",
        "      video_path: File path to the video.\n",
        "      n_frames: Number of frames to be created per video file.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "  \"\"\"\n",
        "  # Read each video frame by frame\n",
        "  video_annotations = get_video_annotations(video_path)\n",
        "  result = []\n",
        "  src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  need_length = n_frames\n",
        "  if video_annotations['anomaly_1_start'] == -1:\n",
        "    if need_length > video_length:\n",
        "      start = 0\n",
        "      end = video_length\n",
        "    else:\n",
        "      max_start = video_length - need_length\n",
        "      start = random.randint(0, max_start)\n",
        "      end = start + need_length\n",
        "  else:\n",
        "    start = video_annotations['anomaly_1_start']\n",
        "    end = video_annotations['anomaly_1_end']\n",
        "    if need_length < (end - start):\n",
        "      max_start = end - need_length\n",
        "      start = random.randint(start, max_start)\n",
        "      end = start + need_length\n",
        "\n",
        "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "\n",
        "  for _ in range(n_frames):\n",
        "    ret, frame = src.read()\n",
        "    if ret and frame is not None:\n",
        "      frame = format_frames(frame, output_size)\n",
        "      result.append(frame)\n",
        "    else:\n",
        "      break\n",
        "  src.release()\n",
        "  result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "mfcjyCuM-3en"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset Paths"
      ],
      "metadata": {
        "id": "of2cwEy2tAUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_paths = {}\n",
        "dataset_directory = pathlib.Path('/content/drive/MyDrive/ucf_extracted')\n",
        "dataset_paths['train'] = dataset_directory / 'train'\n",
        "dataset_paths['test'] = dataset_directory / 'test'"
      ],
      "metadata": {
        "id": "kUCjbw8HtNFs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in dataset_paths.values():\n",
        "  assert p.exists() == True"
      ],
      "metadata": {
        "id": "Mf4SoN-ftzk_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_count_train = len(list(dataset_directory.glob('train/*/*.mp4')))\n",
        "video_count_test = len(list(dataset_directory.glob('test/*/*.mp4')))\n",
        "video_total = video_count_train + video_count_test\n",
        "print(f'Total training videos: {video_count_train}')\n",
        "print(f'Total training test: {video_count_test}')\n",
        "print(f\"Total videos: {video_total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeAKdV5OuPBO",
        "outputId": "0f5554b5-2b8f-4eeb-fc66-8d21f642a532"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training videos: 849\n",
            "Total training test: 150\n",
            "Total videos: 999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset Generator\n"
      ],
      "metadata": {
        "id": "spN6fp2yus56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FrameGenerator:\n",
        "  def __init__(self, path, n_frames=num_frames, output_size=(resolution, resolution), frame_step=frame_step, training = False):\n",
        "    \"\"\" Returns a set of frames with their associated label.\n",
        "\n",
        "      Args:\n",
        "        path: Video file paths.\n",
        "        n_frames: Number of frames.\n",
        "        training: Boolean to determine if training dataset is being created.\n",
        "    \"\"\"\n",
        "    self.path = path\n",
        "    self.n_frames = n_frames\n",
        "    self.training = training\n",
        "    self.output_size = output_size\n",
        "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
        "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
        "\n",
        "  def get_files_and_class_names(self):\n",
        "    video_paths = list(self.path.glob('*/*.mp4'))\n",
        "    classes = [p.parent.name for p in video_paths]\n",
        "    return video_paths, classes\n",
        "\n",
        "  def __call__(self):\n",
        "    video_paths, classes = self.get_files_and_class_names()\n",
        "    pairs = list(zip(video_paths, classes))\n",
        "    if self.training:\n",
        "      random.shuffle(pairs)\n",
        "    for path, name in pairs:\n",
        "      try:\n",
        "        video_frames = frames_from_video_file(path, self.n_frames, output_size=self.output_size, frame_step=frame_step)\n",
        "      except Exception as exc:\n",
        "        print(f'Error on {path}')\n",
        "        print(exc)\n",
        "        continue\n",
        "      label = self.class_ids_for_name[name] # Encode labels\n",
        "      yield video_frames, label\n"
      ],
      "metadata": {
        "id": "UtaJ5n13uwvv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_signature = (tf.TensorSpec(shape =(None, resolution, resolution, 3), dtype = tf.float32),\n",
        "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(dataset_paths['train'], training = True),\n",
        "                                          output_signature=output_signature\n",
        "                                          )\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(FrameGenerator(dataset_paths['test']),\n",
        "                                        output_signature=output_signature\n",
        "                                         )\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "JrHUIK7PvfvA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frames, labels in train_ds.take(1):\n",
        "  print(f\"Frames Shape: {frames.shape}, Dtype: {frames.dtype}\")\n",
        "  print(f\"Label Shape: {labels.shape}, Dtype: {labels.dtype}\")"
      ],
      "metadata": {
        "id": "4UR5-EbI3Rtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac0cf1e-9ad6-41fa-8603-eaa5d37b087e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames Shape: (1, 64, 172, 172, 3), Dtype: <dtype: 'float32'>\n",
            "Label Shape: (1,), Dtype: <dtype: 'int16'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "# test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "mWWG0-u99FQM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Loading"
      ],
      "metadata": {
        "id": "E4V56xn8xWnG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmdzt6Eu9Afp"
      },
      "source": [
        "### Construct the backbone with proper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "msnxCHSa9Cb2"
      },
      "outputs": [],
      "source": [
        "use_positional_encoding = model_id in {'a3', 'a4', 'a5'}\n",
        "\n",
        "backbone = movinet.Movinet(\n",
        "    model_id=model_id,\n",
        "    causal=True,\n",
        "    conv_type='2plus1d',\n",
        "    se_type='2plus3d',\n",
        "    activation='hard_swish',\n",
        "    gating_activation='hard_sigmoid',\n",
        "    use_positional_encoding=use_positional_encoding,\n",
        "    use_external_states=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSCnGqY69IzG"
      },
      "source": [
        "### Construct the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "n5m9qZ__eo92"
      },
      "outputs": [],
      "source": [
        "if not start_from_checkpoint:\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone,\n",
        "      num_classes=600,\n",
        "      output_states=True)\n",
        "\n",
        "  model.build(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jfwRvD59RyX"
      },
      "source": [
        "### Load the pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g7y8zwcz9SJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00d529b-173a-47ed-dc15-857d751d60a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movinet_a0_stream/\n",
            "movinet_a0_stream/ckpt-1.data-00000-of-00001\n",
            "movinet_a0_stream/ckpt-1.index\n",
            "movinet_a0_stream/checkpoint\n"
          ]
        }
      ],
      "source": [
        "if not start_from_checkpoint:\n",
        "  # Extract pretrained weights\n",
        "  !wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_stream.tar.gz -O movinet_a0_stream.tar.gz -q\n",
        "  !tar -xvf movinet_a0_stream.tar.gz\n",
        "\n",
        "  checkpoint_dir = 'movinet_a0_stream'\n",
        "  checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "  checkpoint = tf.train.Checkpoint(model=model)\n",
        "  status = checkpoint.restore(checkpoint_path)\n",
        "  status.assert_existing_objects_matched()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0MyBsZnTrnh"
      },
      "source": [
        "### Set up the distribution strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IHyqT0csQvRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe37afb-8722-446a-da07-29d51640536c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on single GPU  /device:GPU:0\n",
            "Number of accelerators:  1\n"
          ]
        }
      ],
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu_resolver = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "  tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n",
        "  print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "  distribution_strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  distribution_strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  distribution_strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "\n",
        "print(\"Number of accelerators: \", distribution_strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmPbIku_9ejS"
      },
      "source": [
        "### Construct custom classifier with required number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lpXf9GFWlE2-"
      },
      "outputs": [],
      "source": [
        "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes, dropout_rate, bias_regularizer):\n",
        "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone=backbone,\n",
        "      num_classes=num_classes,\n",
        "      dropout_rate=dropout_rate,\n",
        "      bias_regularizer=tf.keras.regularizers.L2(bias_regularizer))\n",
        "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Construct loss, optimizer and compile the model\n",
        "with distribution_strategy.scope():\n",
        "  model = build_classifier(batch_size, None, resolution, backbone, num_classes, dropout_rate, bias_regularizer)\n",
        "  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "  model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start From Previous Checkpoint"
      ],
      "metadata": {
        "id": "0o9sYkeu1Pwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if start_from_checkpoint:\n",
        "  model.load_weights(tf.train.latest_checkpoint(paths['checkpoints_dir']))\n",
        "  print('Loading from: ',tf.train.latest_checkpoint(paths['checkpoints_dir']))"
      ],
      "metadata": {
        "id": "w_GyI3Ho1Tm-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3S6pmEO9y9w"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=paths['checkpoints_dir'] / 'cp.ckpt',\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "OWbdFNdk2_Ic"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_ds,\n",
        "                    validation_data=test_ds,\n",
        "                    epochs=epochs,\n",
        "                    validation_freq=1,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "P5Q7qA5hxOD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1984cd7f-95ec-457b-83a1-45547e735af5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "    849/Unknown - 1131s 1s/step - loss: 0.6046 - accuracy: 0.7067\n",
            "Epoch 1: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1342s 2s/step - loss: 0.6046 - accuracy: 0.7067 - val_loss: 0.9428 - val_accuracy: 0.6067\n",
            "Epoch 2/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.7809\n",
            "Epoch 2: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1348s 2s/step - loss: 0.4984 - accuracy: 0.7809 - val_loss: 0.6929 - val_accuracy: 0.6467\n",
            "Epoch 3/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.8174\n",
            "Epoch 3: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1303s 2s/step - loss: 0.4344 - accuracy: 0.8174 - val_loss: 0.8772 - val_accuracy: 0.6467\n",
            "Epoch 4/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8351\n",
            "Epoch 4: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1288s 2s/step - loss: 0.3978 - accuracy: 0.8351 - val_loss: 0.6506 - val_accuracy: 0.6733\n",
            "Epoch 5/5\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8398\n",
            "Epoch 5: saving model to /content/drive/MyDrive/ucf_dataset/checkpoints/a0/a0_stream_5.0/cp.ckpt\n",
            "849/849 [==============================] - 1288s 2s/step - loss: 0.3494 - accuracy: 0.8398 - val_loss: 0.9759 - val_accuracy: 0.5733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "z38g9CV9x7W6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot History"
      ],
      "metadata": {
        "id": "RwpiMfItyXDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "%matplotlib inline\n",
        "plt.figure()\n",
        "plot_training_history(results)"
      ],
      "metadata": {
        "id": "uthxcrfFyS9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "8be0894d-7f6a-4736-d498-6e8b769da092"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting Model"
      ],
      "metadata": {
        "id": "tNvQGrqiAAV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reconstruct the whole model with use_external_states=True to make the inference using states."
      ],
      "metadata": {
        "id": "qZUK0Rqv21uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if export_model:\n",
        "  model_id = 'a0'\n",
        "  use_positional_encoding = model_id in {'a3', 'a4', 'a5'}\n",
        "\n",
        "  # Create backbone and model.\n",
        "  backbone = movinet.Movinet(\n",
        "      model_id=model_id,\n",
        "      causal=True,\n",
        "      conv_type='2plus1d',\n",
        "      se_type='2plus3d',\n",
        "      activation='hard_swish',\n",
        "      gating_activation='hard_sigmoid',\n",
        "      use_positional_encoding=use_positional_encoding,\n",
        "      use_external_states=True,\n",
        "  )\n",
        "\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone,\n",
        "      num_classes=num_classes,\n",
        "      output_states=True)\n",
        "\n",
        "\n",
        "  # [Optional] Build the model and load a pretrained checkpoint.\n",
        "  model.build(input_shape)\n",
        "\n",
        "  # Load weights from the checkpoint to the rebuilt model\n",
        "  model.load_weights(tf.train.latest_checkpoint(paths['checkpoints_dir']))"
      ],
      "metadata": {
        "id": "vmd7kZL4nQ9S"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export to saved model"
      ],
      "metadata": {
        "id": "HEYDIVSr3NUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if export_model:\n",
        "  saved_model_dir = paths['models'] / export_model_name\n",
        "  tflite_filename = paths['tflite']  / (export_model_name + \".tflite\")\n",
        "  # Convert to saved model\n",
        "  export_saved_model.export_saved_model(\n",
        "      model=model,\n",
        "      input_shape=[1, 1, resolution, resolution, 3],\n",
        "      export_path=saved_model_dir,\n",
        "      causal=True,\n",
        "      bundle_input_init_states_fn=False)"
      ],
      "metadata": {
        "id": "reOX9Zskneql"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to TF Lite"
      ],
      "metadata": {
        "id": "pePv8slH4yOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if export_model:\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(str(saved_model_dir))\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  with open(tflite_filename, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "nFXGX9nr4xeU"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}